{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d56962",
   "metadata": {},
   "source": [
    "# 01. Data Preparation for Food Similarity Model\n",
    "\n",
    "This notebook handles the initial data loading, exploration, preprocessing, and feature preparation for the KNN food similarity model.\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "- Load and explore the cleaned nutritional dataset\n",
    "- Prepare features for similarity analysis\n",
    "- Perform feature scaling and create evaluation subsets\n",
    "- Set up food lookup structures for similarity queries\n",
    "\n",
    "**Note**: This is the first step in building a food similarity recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a0cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data preparation libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for data preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(10)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"üìä Data preparation libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a29a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (10000, 13)\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             10000 non-null  object \n",
      " 1   food_item      10000 non-null  object \n",
      " 2   category       10000 non-null  object \n",
      " 3   calories       10000 non-null  int64  \n",
      " 4   proteins       10000 non-null  float64\n",
      " 5   carbohydrates  10000 non-null  float64\n",
      " 6   fats           10000 non-null  float64\n",
      " 7   fibers         10000 non-null  float64\n",
      " 8   sugars         10000 non-null  float64\n",
      " 9   sodium         10000 non-null  int64  \n",
      " 10  cholesterol    10000 non-null  int64  \n",
      " 11  meal_type      10000 non-null  object \n",
      " 12  water_intake   10000 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(4)\n",
      "memory usage: 1015.8+ KB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "                         id       food_item category  calories  proteins  \\\n",
      "0  6843fa1e7fe66773fab3281d            Eggs     Meat       173      42.4   \n",
      "1  6843fa1e7fe66773fab3281e           Apple   Fruits        66      39.2   \n",
      "2  6843fa1e7fe66773fab3281f  Chicken Breast     Meat       226      27.1   \n",
      "3  6843fa1e7fe66773fab32820          Banana   Fruits       116      43.4   \n",
      "4  6843fa1e7fe66773fab32821          Banana   Fruits       500      33.9   \n",
      "\n",
      "   carbohydrates  fats  fibers  sugars  sodium  cholesterol  meal_type  \\\n",
      "0           83.7   1.5     1.5    12.7     752          125      Lunch   \n",
      "1           13.8   3.2     2.6    12.2     680           97      Lunch   \n",
      "2           79.1  25.8     3.2    44.7     295          157  Breakfast   \n",
      "3           47.1  16.1     6.5    44.1     307           13      Snack   \n",
      "4           75.8  47.0     7.8    19.4     358          148      Lunch   \n",
      "\n",
      "   water_intake  \n",
      "0           478  \n",
      "1           466  \n",
      "2           635  \n",
      "3           379  \n",
      "4           471  \n",
      "\n",
      "Target variable distribution:\n",
      "category\n",
      "Dairy         1460\n",
      "Fruits        1453\n",
      "Beverages     1445\n",
      "Snacks        1432\n",
      "Meat          1418\n",
      "Vegetables    1408\n",
      "Grains        1384\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('../../dataset/daily_food_nutrition_dataset_cleaned.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28dd981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Data Quality Assessment\n",
      "========================================\n",
      "Checking for missing values:\n",
      "id               0\n",
      "food_item        0\n",
      "category         0\n",
      "calories         0\n",
      "proteins         0\n",
      "carbohydrates    0\n",
      "fats             0\n",
      "fibers           0\n",
      "sugars           0\n",
      "sodium           0\n",
      "cholesterol      0\n",
      "meal_type        0\n",
      "water_intake     0\n",
      "dtype: int64\n",
      "\n",
      "Dataset Summary:\n",
      "- Total records: 10,000\n",
      "- Unique food items: 35\n",
      "- Food categories: 7\n",
      "- Duplicate records: 0\n",
      "\n",
      "Food distribution by category:\n",
      "  Dairy: 1,460 (14.6%)\n",
      "  Fruits: 1,453 (14.5%)\n",
      "  Beverages: 1,445 (14.4%)\n",
      "  Snacks: 1,432 (14.3%)\n",
      "  Meat: 1,418 (14.2%)\n",
      "  Vegetables: 1,408 (14.1%)\n",
      "  Grains: 1,384 (13.8%)\n",
      "\n",
      "Example food items by category:\n",
      "  Meat: Eggs, Chicken Breast, Beef Steak\n",
      "  Fruits: Apple, Banana, Grapes\n",
      "  Grains: Oats, Quinoa, Pasta\n",
      "  Vegetables: Carrot, Tomato, Broccoli\n",
      "  Snacks: Cookies, Nuts, Chocolate\n"
     ]
    }
   ],
   "source": [
    "# Data exploration and quality checks\n",
    "print(\"üîç Data Quality Assessment\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"Checking for missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"- Total records: {len(df):,}\")\n",
    "print(f\"- Unique food items: {df['food_item'].nunique():,}\")\n",
    "print(f\"- Food categories: {df['category'].nunique()}\")\n",
    "print(f\"- Duplicate records: {df.duplicated().sum()}\")\n",
    "\n",
    "# Show food distribution by category\n",
    "print(f\"\\nFood distribution by category:\")\n",
    "category_counts = df['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {category}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Show some example food items per category\n",
    "print(f\"\\nExample food items by category:\")\n",
    "for category in df['category'].unique()[:5]:\n",
    "    foods_in_category = df[df['category'] == category]['food_item'].unique()[:3]\n",
    "    print(f\"  {category}: {', '.join(foods_in_category)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "033ffa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü•ó Feature Preparation for Food Similarity\n",
      "==================================================\n",
      "Features selected: ['calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'sodium', 'cholesterol']\n",
      "Features shape: (10000, 8)\n",
      "Unique food items: 35\n",
      "Food categories: 7\n",
      "\n",
      "üìä Nutritional Feature Statistics:\n",
      "       calories  proteins  carbohydrates      fats    fibers    sugars  \\\n",
      "count  10000.00  10000.00       10000.00  10000.00  10000.00  10000.00   \n",
      "mean     327.69     25.52          52.57     25.44      4.99     25.05   \n",
      "std      158.19     14.13          27.39     14.15      2.86     14.48   \n",
      "min       50.00      1.00           5.00      1.00      0.00      0.00   \n",
      "25%      190.00     13.20          28.80     13.30      2.50     12.50   \n",
      "50%      328.00     25.50          52.80     25.30      5.00     25.00   \n",
      "75%      464.00     37.70          76.40     37.60      7.50     37.70   \n",
      "max      600.00     50.00         100.00     50.00     10.00     50.00   \n",
      "\n",
      "         sodium  cholesterol  \n",
      "count  10000.00     10000.00  \n",
      "mean     497.97       151.89  \n",
      "std      287.99        87.36  \n",
      "min        0.00         0.00  \n",
      "25%      249.75        76.00  \n",
      "50%      495.00       153.00  \n",
      "75%      749.00       228.00  \n",
      "max     1000.00       300.00  \n",
      "\n",
      "‚ö†Ô∏è  Feature Range Analysis:\n",
      "  calories: Range [50.0, 600.0], Outliers: 0\n",
      "  proteins: Range [1.0, 50.0], Outliers: 0\n",
      "  carbohydrates: Range [5.0, 100.0], Outliers: 0\n",
      "  fats: Range [1.0, 50.0], Outliers: 0\n",
      "  fibers: Range [0.0, 10.0], Outliers: 0\n",
      "  sugars: Range [0.0, 50.0], Outliers: 0\n",
      "  sodium: Range [0.0, 1000.0], Outliers: 0\n",
      "  cholesterol: Range [0.0, 300.0], Outliers: 0\n"
     ]
    }
   ],
   "source": [
    "# Define and prepare features for similarity analysis\n",
    "print(\"ü•ó Feature Preparation for Food Similarity\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define nutritional features for KNN food similarity model\n",
    "feature_columns = ['calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'sodium', 'cholesterol']\n",
    "X = df[feature_columns]\n",
    "\n",
    "# Keep food items and categories for analysis (not for prediction)\n",
    "food_items = df['food_item']\n",
    "categories = df['category']\n",
    "\n",
    "print(f\"Features selected: {feature_columns}\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Unique food items: {food_items.nunique()}\")\n",
    "print(f\"Food categories: {categories.nunique()}\")\n",
    "\n",
    "# Display feature statistics\n",
    "print(f\"\\nüìä Nutritional Feature Statistics:\")\n",
    "print(X.describe().round(2))\n",
    "\n",
    "# Check for any extreme values or outliers\n",
    "print(f\"\\n‚ö†Ô∏è  Feature Range Analysis:\")\n",
    "for col in feature_columns:\n",
    "    q1 = X[col].quantile(0.25)\n",
    "    q3 = X[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = X[(X[col] < lower_bound) | (X[col] > upper_bound)][col].count()\n",
    "    print(f\"  {col}: Range [{X[col].min():.1f}, {X[col].max():.1f}], Outliers: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c830f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è  Feature Scaling and Data Preparation\n",
      "==================================================\n",
      "Original features shape: (10000, 8)\n",
      "Scaled features shape: (10000, 8)\n",
      "‚úÖ Features scaled successfully!\n",
      "\n",
      "Scaling verification:\n",
      "- Scaled features mean: [ 0. -0. -0.  0.  0. -0.  0.  0.]\n",
      "- Scaled features std: [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "üìö Food lookup table created with 10000 entries\n",
      "Sample lookup entries:\n",
      "   index       food_item    category\n",
      "0      0            Eggs        Meat\n",
      "1      1           Apple      Fruits\n",
      "2      2  Chicken Breast        Meat\n",
      "3      3          Banana      Fruits\n",
      "4      4          Banana      Fruits\n",
      "5      5            Oats      Grains\n",
      "6      6          Carrot  Vegetables\n",
      "7      7         Cookies      Snacks\n",
      "8      8           Apple      Fruits\n",
      "9      9          Quinoa      Grains\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling and data preparation for similarity analysis\n",
    "print(\"‚öñÔ∏è  Feature Scaling and Data Preparation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Feature scaling - essential for KNN distance calculations\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Original features shape: {X.shape}\")\n",
    "print(f\"Scaled features shape: {X_scaled.shape}\")\n",
    "print(f\"‚úÖ Features scaled successfully!\")\n",
    "\n",
    "# Verify scaling worked correctly\n",
    "print(f\"\\nScaling verification:\")\n",
    "print(f\"- Scaled features mean: {np.mean(X_scaled, axis=0).round(4)}\")\n",
    "print(f\"- Scaled features std: {np.std(X_scaled, axis=0).round(4)}\")\n",
    "\n",
    "# Create a food lookup dataframe for easy access during similarity queries\n",
    "food_lookup = pd.DataFrame({\n",
    "    'index': range(len(df)),\n",
    "    'food_item': food_items,\n",
    "    'category': categories\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nüìö Food lookup table created with {len(food_lookup)} entries\")\n",
    "print(f\"Sample lookup entries:\")\n",
    "print(food_lookup.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ba1915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Creating Evaluation Subset\n",
      "========================================\n",
      "Evaluation subset size: 1000 samples\n",
      "Evaluation percentage: 10.0%\n",
      "\n",
      "Category distribution in evaluation set:\n",
      "  Snacks: 153 (15.3%)\n",
      "  Beverages: 149 (14.9%)\n",
      "  Dairy: 145 (14.5%)\n",
      "  Vegetables: 142 (14.2%)\n",
      "  Meat: 140 (14.0%)\n",
      "  Grains: 136 (13.6%)\n",
      "  Fruits: 135 (13.5%)\n",
      "\n",
      "‚úÖ Evaluation subset created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create evaluation subset for model testing\n",
    "print(\"üéØ Creating Evaluation Subset\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# For evaluation, we'll create a representative subset\n",
    "np.random.seed(42)\n",
    "eval_size = min(1000, len(X_scaled))\n",
    "eval_indices = np.random.choice(len(X_scaled), size=eval_size, replace=False)\n",
    "\n",
    "X_eval = X_scaled[eval_indices]\n",
    "food_eval = food_lookup.iloc[eval_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Evaluation subset size: {len(X_eval)} samples\")\n",
    "print(f\"Evaluation percentage: {(len(X_eval) / len(X_scaled)) * 100:.1f}%\")\n",
    "\n",
    "# Check category distribution in evaluation set\n",
    "eval_category_dist = food_eval['category'].value_counts()\n",
    "print(f\"\\nCategory distribution in evaluation set:\")\n",
    "for category, count in eval_category_dist.items():\n",
    "    percentage = (count / len(food_eval)) * 100\n",
    "    print(f\"  {category}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation subset created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f7bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving Prepared Data\n",
      "==============================\n",
      "‚úÖ Saved feature scaler\n",
      "‚úÖ Saved scaled features\n",
      "‚úÖ Saved food lookup table\n",
      "‚úÖ Saved evaluation subset\n",
      "‚úÖ Saved feature information\n",
      "\n",
      "üéâ Data preparation complete! Ready for model training.\n",
      "üìÅ Saved files in '../models/' directory:\n",
      "   ‚Ä¢ feature_scaler.pkl - StandardScaler for feature normalization\n",
      "   ‚Ä¢ X_scaled.pkl - Scaled feature matrix\n",
      "   ‚Ä¢ food_lookup.pkl - Food item lookup table\n",
      "   ‚Ä¢ eval_subset.pkl - Evaluation subset for testing\n",
      "   ‚Ä¢ feature_info.pkl - Feature metadata and dataset info\n",
      "‚úÖ Saved feature scaler\n",
      "‚úÖ Saved scaled features\n",
      "‚úÖ Saved food lookup table\n",
      "‚úÖ Saved evaluation subset\n",
      "‚úÖ Saved feature information\n",
      "\n",
      "üéâ Data preparation complete! Ready for model training.\n",
      "üìÅ Saved files in '../models/' directory:\n",
      "   ‚Ä¢ feature_scaler.pkl - StandardScaler for feature normalization\n",
      "   ‚Ä¢ X_scaled.pkl - Scaled feature matrix\n",
      "   ‚Ä¢ food_lookup.pkl - Food item lookup table\n",
      "   ‚Ä¢ eval_subset.pkl - Evaluation subset for testing\n",
      "   ‚Ä¢ feature_info.pkl - Feature metadata and dataset info\n"
     ]
    }
   ],
   "source": [
    "# Save prepared data for next notebooks\n",
    "print(\"üíæ Saving Prepared Data\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the prepared data components\n",
    "import joblib\n",
    "\n",
    "# Save scaler for consistent feature scaling\n",
    "joblib.dump(scaler, '../models/feature_scaler.pkl')\n",
    "print(\"‚úÖ Saved feature scaler\")\n",
    "\n",
    "# Save scaled features\n",
    "joblib.dump(X_scaled, '../models/X_scaled.pkl')\n",
    "print(\"‚úÖ Saved scaled features\")\n",
    "\n",
    "# Save food lookup table\n",
    "joblib.dump(food_lookup, '../models/food_lookup.pkl')\n",
    "print(\"‚úÖ Saved food lookup table\")\n",
    "\n",
    "# Save evaluation subset\n",
    "joblib.dump({'X_eval': X_eval, 'food_eval': food_eval}, '../models/eval_subset.pkl')\n",
    "print(\"‚úÖ Saved evaluation subset\")\n",
    "\n",
    "# Save feature information\n",
    "feature_info = {\n",
    "    'feature_columns': feature_columns,\n",
    "    'dataset_shape': df.shape,\n",
    "    'n_foods': len(food_lookup),\n",
    "    'n_categories': len(categories.unique()),\n",
    "    'categories': sorted(categories.unique())\n",
    "}\n",
    "joblib.dump(feature_info, '../models/feature_info.pkl')\n",
    "print(\"‚úÖ Saved feature information\")\n",
    "\n",
    "print(f\"\\nüéâ Data preparation complete! Ready for model training.\")\n",
    "print(f\"üìÅ Saved files in '../models/' directory:\")\n",
    "print(f\"   ‚Ä¢ feature_scaler.pkl - StandardScaler for feature normalization\")\n",
    "print(f\"   ‚Ä¢ X_scaled.pkl - Scaled feature matrix\")\n",
    "print(f\"   ‚Ä¢ food_lookup.pkl - Food item lookup table\")\n",
    "print(f\"   ‚Ä¢ eval_subset.pkl - Evaluation subset for testing\")\n",
    "print(f\"   ‚Ä¢ feature_info.pkl - Feature metadata and dataset info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79fec6",
   "metadata": {},
   "source": [
    "## Data Preparation Summary\n",
    "\n",
    "This notebook prepared the foundation for food similarity analysis:\n",
    "\n",
    "### ‚úÖ Completed Tasks:\n",
    "1. **Data Loading**: Loaded {dataset_shape[0]:,} food items with {len(feature_columns)} nutritional features\n",
    "2. **Quality Assessment**: Verified data integrity and explored distributions\n",
    "3. **Feature Scaling**: Applied StandardScaler for consistent KNN distance calculations\n",
    "4. **Lookup Creation**: Built food lookup table for similarity queries\n",
    "5. **Evaluation Setup**: Created representative test subset for model validation\n",
    "6. **Data Persistence**: Saved all prepared components for subsequent notebooks\n",
    "\n",
    "### üìä Dataset Overview:\n",
    "- **Food Items**: {n_foods:,} unique foods across {n_categories} categories\n",
    "- **Features**: {feature_columns}\n",
    "- **Scaling**: Mean=0, Std=1 for optimal KNN performance\n",
    "\n",
    "### ‚û°Ô∏è Next Steps:\n",
    "Continue to **02_baseline_models.ipynb** to create initial KNN models and establish baseline performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
