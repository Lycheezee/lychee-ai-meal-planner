{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466091a7",
   "metadata": {},
   "source": [
    "# Clean Unified Food Dataset\n",
    "\n",
    "This notebook cleans the unified food dataset by:\n",
    "\n",
    "1. Removing duplicate food items\n",
    "2. Removing food items with special characters\n",
    "3. Creating a final clean dataset for production use\n",
    "\n",
    "## Input File\n",
    "\n",
    "- `../../dataset/childs/unified_food_dataset.csv`\n",
    "\n",
    "## Output File\n",
    "\n",
    "- `../../dataset/childs/final_clean_food_dataset.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddff27d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading unified dataset from: ../../dataset/childs/unified_food_dataset.csv\n",
      "Original dataset shape: (20944, 13)\n",
      "Original columns: ['food_item', 'calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'category', 'sodium', 'cholesterol', 'meal_type', 'water_intake', 'source_file']\n",
      "Total food items: 10372\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Load the unified dataset\n",
    "input_file = '../../dataset/childs/unified_food_dataset.csv'\n",
    "print(f\"Loading unified dataset from: {input_file}\")\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Original columns: {list(df.columns)}\")\n",
    "print(f\"Total food items: {df['food_item'].nunique() if 'food_item' in df.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff8c397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL DATA OVERVIEW:\n",
      "==================================================\n",
      "Dataset shape: (20944, 13)\n",
      "Columns: ['food_item', 'calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'category', 'sodium', 'cholesterol', 'meal_type', 'water_intake', 'source_file']\n",
      "\n",
      "Unique food items: 10372\n",
      "Total rows: 20944\n",
      "Duplicate food items: 10572\n",
      "\n",
      "Sample food items (first 10):\n",
      "  1. Tomato And Anchovy Pasta\n",
      "  2. Blueberry Cream Muffins\n",
      "  3. One-Pot Lemon Garlic Shrimp Pasta\n",
      "  4. One-Pot Garlic Parmesan Pasta\n",
      "  5. Chocolate Mug Cake\n",
      "  6. 3-Ingredient Teriyaki Chicken\n",
      "  7. 3 Ingredient Peanut Butter Cookies\n",
      "  8. Garlic Shrimp Bacon Alfredo\n",
      "  9. Creamy Cajun Pasta\n",
      "  10. Creamy Chicken Penne Pasta\n",
      "\n",
      "Distribution by source file:\n",
      "  - Food_2.csv: 10,000 rows\n",
      "  - Food_4.csv: 8,790 rows\n",
      "  - Food_5.csv: 1,460 rows\n",
      "  - Food_3.csv: 656 rows\n",
      "  - Food_1.csv: 38 rows\n"
     ]
    }
   ],
   "source": [
    "# Display initial data overview\n",
    "print(\"INITIAL DATA OVERVIEW:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "if 'food_item' in df.columns:\n",
    "    print(f\"\\nUnique food items: {df['food_item'].nunique()}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Duplicate food items: {len(df) - df['food_item'].nunique()}\")\n",
    "    \n",
    "    # Show some sample food items\n",
    "    print(f\"\\nSample food items (first 10):\")\n",
    "    for i, item in enumerate(df['food_item'].head(10)):\n",
    "        print(f\"  {i+1}. {item}\")\n",
    "        \n",
    "    # Show distribution by source file\n",
    "    if 'source_file' in df.columns:\n",
    "        print(f\"\\nDistribution by source file:\")\n",
    "        source_counts = df['source_file'].value_counts()\n",
    "        for source, count in source_counts.items():\n",
    "            print(f\"  - {source}: {count:,} rows\")\n",
    "else:\n",
    "    print(\"No 'food_item' column found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf669d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING SPECIAL CHARACTER DETECTION:\n",
      "==================================================\n",
      "'Apple' -> Special chars: False, Valid: True\n",
      "'Chicken Breast' -> Special chars: False, Valid: True\n",
      "'Tomato & Basil' -> Special chars: False, Valid: True\n",
      "'123' -> Special chars: False, Valid: False\n",
      "'' -> Special chars: False, Valid: False\n",
      "'Food™' -> Special chars: True, Valid: True\n",
      "'Rice (Brown)' -> Special chars: False, Valid: True\n",
      "'Milk - 2%' -> Special chars: True, Valid: True\n",
      "'Café Latte' -> Special chars: True, Valid: True\n",
      "'Fish & Chips' -> Special chars: False, Valid: True\n"
     ]
    }
   ],
   "source": [
    "def has_special_characters(text):\n",
    "    \"\"\"\n",
    "    Check if text contains special characters.\n",
    "    Returns True if text contains characters other than:\n",
    "    - Letters (a-z, A-Z)\n",
    "    - Numbers (0-9)\n",
    "    - Common food punctuation: space, comma, period, apostrophe, hyphen, parentheses\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return True\n",
    "    \n",
    "    # Convert to string\n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Define allowed characters for food names\n",
    "    allowed_chars = set(string.ascii_letters + string.digits + \" ,.'-()&/\")\n",
    "    \n",
    "    # Check if all characters in the text are allowed\n",
    "    text_chars = set(text)\n",
    "    has_special = not text_chars.issubset(allowed_chars)\n",
    "    \n",
    "    return has_special\n",
    "\n",
    "def is_valid_food_name(text):\n",
    "    \"\"\"\n",
    "    Check if the food name is valid (not empty, not just numbers/symbols)\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Must not be empty\n",
    "    if len(text) == 0:\n",
    "        return False\n",
    "    \n",
    "    # Must contain at least one letter\n",
    "    if not any(c.isalpha() for c in text):\n",
    "        return False\n",
    "    \n",
    "    # Must not be too short (less than 2 characters)\n",
    "    if len(text) < 2:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Test the function with some examples\n",
    "test_items = [\n",
    "    \"Apple\",\n",
    "    \"Chicken Breast\",\n",
    "    \"Tomato & Basil\",\n",
    "    \"123\",\n",
    "    \"\",\n",
    "    \"Food™\",\n",
    "    \"Rice (Brown)\",\n",
    "    \"Milk - 2%\",\n",
    "    \"Café Latte\",\n",
    "    \"Fish & Chips\"\n",
    "]\n",
    "\n",
    "print(\"TESTING SPECIAL CHARACTER DETECTION:\")\n",
    "print(\"=\" * 50)\n",
    "for item in test_items:\n",
    "    has_special = has_special_characters(item)\n",
    "    is_valid = is_valid_food_name(item)\n",
    "    print(f\"'{item}' -> Special chars: {has_special}, Valid: {is_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c022a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING CURRENT DATASET:\n",
      "==================================================\n",
      "Missing food items: 0\n",
      "Food items with special characters: 1690\n",
      "Invalid food names: 4\n",
      "\n",
      "Examples of food items with special characters:\n",
      "  1. 'Easy One-Pot Mac ‘n’ Cheese'\n",
      "  2. 'Jacket Potato: The Pizazz'\n",
      "  3. 'CHEESE,COTTAGE,LOWFAT,2% MILKFAT'\n",
      "  4. 'CHEESE,COTTAGE,LOWFAT,1% MILKFAT'\n",
      "  5. 'MILK,WHL,3.25% MILKFAT,W/ ADDED VITAMIN D'\n",
      "  6. 'MILK,PRODUCER,FLUID,3.7% MILKFAT'\n",
      "  7. 'MILK,RED FAT,FLUID,2% MILKFAT,W/ ADDED VIT A & VITAMIN D'\n",
      "  8. 'MILK,RED FAT,FLUID,2% MILKFAT,W/ ADDED NFMS, VIT A & VIT D'\n",
      "  9. 'MILK,RED FAT,FLUID,2% MILKFAT,PROT FORT,W/ ADDED VIT A & D'\n",
      "  10. 'MILK,LOWFAT,FLUID,1% MILKFAT,W/ ADDED VIT A & VITAMIN D'\n",
      "\n",
      "Examples of invalid food names:\n",
      "  1. '100066'\n",
      "  2. '11131861'\n",
      "  3. '20/20'\n",
      "  4. '31290143009'\n",
      "\n",
      "Exact duplicate rows: 8\n",
      "Duplicate food items: 10572\n",
      "\n",
      "Examples of duplicate food items:\n",
      "  'Cookies': 344 occurrences\n",
      "  'Milk': 311 occurrences\n",
      "  'Orange': 308 occurrences\n",
      "  'Pork Chop': 307 occurrences\n",
      "  'Bread': 303 occurrences\n",
      "  'Orange Juice': 302 occurrences\n",
      "  'Carrot': 301 occurrences\n",
      "  'Apple': 299 occurrences\n",
      "  'Chocolate': 299 occurrences\n",
      "  'Yogurt': 298 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Analyze the current dataset for special characters and duplicates\n",
    "print(\"ANALYZING CURRENT DATASET:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'food_item' in df.columns:\n",
    "    # Check for missing values\n",
    "    missing_food_items = df['food_item'].isna().sum()\n",
    "    print(f\"Missing food items: {missing_food_items}\")\n",
    "    \n",
    "    # Check for special characters\n",
    "    df['has_special_chars'] = df['food_item'].apply(has_special_characters)\n",
    "    df['is_valid_name'] = df['food_item'].apply(is_valid_food_name)\n",
    "    \n",
    "    special_char_count = df['has_special_chars'].sum()\n",
    "    invalid_name_count = (~df['is_valid_name']).sum()\n",
    "    \n",
    "    print(f\"Food items with special characters: {special_char_count}\")\n",
    "    print(f\"Invalid food names: {invalid_name_count}\")\n",
    "    \n",
    "    # Show examples of food items with special characters\n",
    "    if special_char_count > 0:\n",
    "        print(f\"\\nExamples of food items with special characters:\")\n",
    "        special_items = df[df['has_special_chars']]['food_item'].head(10)\n",
    "        for i, item in enumerate(special_items):\n",
    "            print(f\"  {i+1}. '{item}'\")\n",
    "    \n",
    "    # Show examples of invalid food names\n",
    "    if invalid_name_count > 0:\n",
    "        print(f\"\\nExamples of invalid food names:\")\n",
    "        invalid_items = df[~df['is_valid_name']]['food_item'].head(10)\n",
    "        for i, item in enumerate(invalid_items):\n",
    "            print(f\"  {i+1}. '{item}'\")\n",
    "    \n",
    "    # Check for exact duplicates\n",
    "    exact_duplicates = df.duplicated().sum()\n",
    "    print(f\"\\nExact duplicate rows: {exact_duplicates}\")\n",
    "    \n",
    "    # Check for duplicate food items\n",
    "    duplicate_food_items = df.duplicated(subset=['food_item']).sum()\n",
    "    print(f\"Duplicate food items: {duplicate_food_items}\")\n",
    "    \n",
    "    if duplicate_food_items > 0:\n",
    "        print(f\"\\nExamples of duplicate food items:\")\n",
    "        duplicated_items = df[df.duplicated(subset=['food_item'], keep=False)]['food_item'].value_counts().head(10)\n",
    "        for item, count in duplicated_items.items():\n",
    "            print(f\"  '{item}': {count} occurrences\")\n",
    "else:\n",
    "    print(\"ERROR: 'food_item' column not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbb221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANING DATASET:\n",
      "==================================================\n",
      "Starting with 20944 rows\n",
      "Step 1 - Removed 0 rows with missing food_item\n",
      "         Remaining: 20944 rows\n",
      "Step 2 - Removed 4 rows with invalid food names\n",
      "         Remaining: 20940 rows\n",
      "Step 3 - Removed 1690 rows with special characters\n",
      "         Remaining: 19250 rows\n",
      "Step 3 - Removed 1690 rows with special characters\n",
      "         Remaining: 19250 rows\n",
      "Step 4 - Removed 7 exact duplicate rows\n",
      "         Remaining: 19243 rows\n",
      "Step 5 - Removed 10562 duplicate food items\n",
      "         Remaining: 8681 rows\n",
      "\n",
      "FINAL CLEANING RESULTS:\n",
      "Original rows: 20944\n",
      "Final rows: 8681\n",
      "Rows removed: 12263\n",
      "Percentage retained: 41.4%\n",
      "Unique food items: 8681\n",
      "Step 4 - Removed 7 exact duplicate rows\n",
      "         Remaining: 19243 rows\n",
      "Step 5 - Removed 10562 duplicate food items\n",
      "         Remaining: 8681 rows\n",
      "\n",
      "FINAL CLEANING RESULTS:\n",
      "Original rows: 20944\n",
      "Final rows: 8681\n",
      "Rows removed: 12263\n",
      "Percentage retained: 41.4%\n",
      "Unique food items: 8681\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset\n",
    "print(\"CLEANING DATASET:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Start with the original dataset\n",
    "df_clean = df.copy()\n",
    "initial_count = len(df_clean)\n",
    "print(f\"Starting with {initial_count} rows\")\n",
    "\n",
    "# Step 1: Remove rows with missing food_item\n",
    "if 'food_item' in df_clean.columns:\n",
    "    before = len(df_clean)\n",
    "    df_clean = df_clean.dropna(subset=['food_item'])\n",
    "    after = len(df_clean)\n",
    "    print(f\"Step 1 - Removed {before - after} rows with missing food_item\")\n",
    "    print(f\"         Remaining: {after} rows\")\n",
    "\n",
    "# Step 2: Remove rows with invalid food names\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[df_clean['food_item'].apply(is_valid_food_name)]\n",
    "after = len(df_clean)\n",
    "print(f\"Step 2 - Removed {before - after} rows with invalid food names\")\n",
    "print(f\"         Remaining: {after} rows\")\n",
    "\n",
    "# Step 3: Remove rows with special characters\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[~df_clean['food_item'].apply(has_special_characters)]\n",
    "after = len(df_clean)\n",
    "print(f\"Step 3 - Removed {before - after} rows with special characters\")\n",
    "print(f\"         Remaining: {after} rows\")\n",
    "\n",
    "# Step 4: Remove exact duplicate rows\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "after = len(df_clean)\n",
    "print(f\"Step 4 - Removed {before - after} exact duplicate rows\")\n",
    "print(f\"         Remaining: {after} rows\")\n",
    "\n",
    "# Step 5: Remove duplicate food items (keep first occurrence)\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates(subset=['food_item'], keep='first')\n",
    "after = len(df_clean)\n",
    "print(f\"Step 5 - Removed {before - after} duplicate food items\")\n",
    "print(f\"         Remaining: {after} rows\")\n",
    "\n",
    "# Remove temporary columns\n",
    "if 'has_special_chars' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(['has_special_chars', 'is_valid_name'], axis=1)\n",
    "\n",
    "print(f\"\\nFINAL CLEANING RESULTS:\")\n",
    "print(f\"Original rows: {initial_count}\")\n",
    "print(f\"Final rows: {len(df_clean)}\")\n",
    "print(f\"Rows removed: {initial_count - len(df_clean)}\")\n",
    "print(f\"Percentage retained: {len(df_clean) / initial_count * 100:.1f}%\")\n",
    "print(f\"Unique food items: {df_clean['food_item'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30a6473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING NUTRITIONAL VALUE CLEANING:\n",
      "==================================================\n",
      "'3,170 kj\n",
      "(758 kcal)' -> 758.0\n",
      "'17.2 g' -> 17.2\n",
      "'8.97 g' -> 8.97\n",
      "'71.7 g' -> 71.7\n",
      "'0 g' -> 0.0\n",
      "'0%' -> 0.0\n",
      "'33.33%' -> 33.33\n",
      "'50.2 kj\n",
      "(12 kcal)' -> 12.0\n",
      "'0.96 g' -> 0.96\n",
      "'0.62 g' -> 0.62\n",
      "'' -> None\n",
      "'None' -> None\n",
      "'1,234.56 mg' -> 1234.56\n"
     ]
    }
   ],
   "source": [
    "def clean_nutritional_value(value):\n",
    "    \"\"\"\n",
    "    Clean nutritional values by removing units and extracting numeric values.\n",
    "    Handles formats like:\n",
    "    - '3,170 kj (758 kcal)' -> 758 (extracts kcal from parentheses)\n",
    "    - '17.2 g' -> 17.2\n",
    "    - '0%' -> 0\n",
    "    - '33.33%' -> 33.33\n",
    "    - '50.2 kj (12 kcal)' -> 12\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value == '':\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # Handle empty or just whitespace\n",
    "    if not value_str:\n",
    "        return None\n",
    "    \n",
    "    # For energy values, prefer kcal over kj (extract from parentheses)\n",
    "    if 'kcal' in value_str.lower():\n",
    "        # Extract kcal value from parentheses like \"(758 kcal)\"\n",
    "        kcal_match = re.search(r'\\((\\d+(?:,\\d+)*(?:\\.\\d+)?)\\s*kcal\\)', value_str, re.IGNORECASE)\n",
    "        if kcal_match:\n",
    "            return float(kcal_match.group(1).replace(',', ''))\n",
    "    \n",
    "    # Remove common units and extract numeric value\n",
    "    # Remove units: g, kg, mg, %, kj, kcal, ml, l\n",
    "    cleaned = re.sub(r'\\s*(?:kj|kcal|mg|kg|ml|l|g|%)\\s*', ' ', value_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove parentheses and their contents\n",
    "    cleaned = re.sub(r'\\([^)]*\\)', '', cleaned)\n",
    "    \n",
    "    # Extract first numeric value (with commas and decimals)\n",
    "    numeric_match = re.search(r'(\\d+(?:,\\d+)*(?:\\.\\d+)?)', cleaned)\n",
    "    \n",
    "    if numeric_match:\n",
    "        numeric_str = numeric_match.group(1).replace(',', '')\n",
    "        try:\n",
    "            return float(numeric_str)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test the function with sample values\n",
    "test_values = [\n",
    "    \"3,170 kj\\n(758 kcal)\",\n",
    "    \"17.2 g\",\n",
    "    \"8.97 g\", \n",
    "    \"71.7 g\",\n",
    "    \"0 g\",\n",
    "    \"0%\",\n",
    "    \"33.33%\",\n",
    "    \"50.2 kj\\n(12 kcal)\",\n",
    "    \"0.96 g\",\n",
    "    \"0.62 g\",\n",
    "    \"\",\n",
    "    None,\n",
    "    \"1,234.56 mg\"\n",
    "]\n",
    "\n",
    "print(\"TESTING NUTRITIONAL VALUE CLEANING:\")\n",
    "print(\"=\" * 50)\n",
    "for value in test_values:\n",
    "    cleaned = clean_nutritional_value(value)\n",
    "    print(f\"'{value}' -> {cleaned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5c153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANED DATASET ANALYSIS:\n",
      "==================================================\n",
      "Final dataset shape: (8681, 13)\n",
      "Columns: ['food_item', 'calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'category', 'sodium', 'cholesterol', 'meal_type', 'water_intake', 'source_file']\n",
      "Unique food items: 8681\n",
      "\n",
      "Distribution by source file after cleaning:\n",
      "  - Food_4.csv: 7,558 rows (87.1%)\n",
      "  - Food_5.csv: 985 rows (11.3%)\n",
      "  - Food_3.csv: 67 rows (0.8%)\n",
      "  - Food_1.csv: 36 rows (0.4%)\n",
      "  - Food_2.csv: 35 rows (0.4%)\n",
      "\n",
      "Nutritional data availability:\n",
      "  - calories: 8525/8681 (98.2%)\n",
      "  - proteins: 8463/8681 (97.5%)\n",
      "  - carbohydrates: 8491/8681 (97.8%)\n",
      "  - fats: 8392/8681 (96.7%)\n",
      "  - fibers: 7631/8681 (87.9%)\n",
      "  - sugars: 6811/8681 (78.5%)\n",
      "  - sodium: 8254/8681 (95.1%)\n",
      "  - cholesterol: 7199/8681 (82.9%)\n",
      "\n",
      "Sample of cleaned food items (first 15):\n",
      "   1. Tomato And Anchovy Pasta\n",
      "   2. Blueberry Cream Muffins\n",
      "   3. One-Pot Lemon Garlic Shrimp Pasta\n",
      "   4. One-Pot Garlic Parmesan Pasta\n",
      "   5. Chocolate Mug Cake\n",
      "   6. 3-Ingredient Teriyaki Chicken\n",
      "   7. 3 Ingredient Peanut Butter Cookies\n",
      "   8. Garlic Shrimp Bacon Alfredo\n",
      "   9. Creamy Cajun Pasta\n",
      "  10. Creamy Chicken Penne Pasta\n",
      "  11. One-Pot Cheeseburger Pasta\n",
      "  12. Garlic Shrimp Scampi\n",
      "  13. One-Pot Broccoli Cheddar Soup\n",
      "  14. Healthy Banana Pancakes\n",
      "  15. Buttermilk Pancakes\n"
     ]
    }
   ],
   "source": [
    "# Analyze the cleaned dataset\n",
    "print(\"CLEANED DATASET ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"Columns: {list(df_clean.columns)}\")\n",
    "\n",
    "if 'food_item' in df_clean.columns:\n",
    "    print(f\"Unique food items: {df_clean['food_item'].nunique()}\")\n",
    "    \n",
    "    # Show distribution by source file\n",
    "    if 'source_file' in df_clean.columns:\n",
    "        print(f\"\\nDistribution by source file after cleaning:\")\n",
    "        source_counts = df_clean['source_file'].value_counts()\n",
    "        for source, count in source_counts.items():\n",
    "            print(f\"  - {source}: {count:,} rows ({count/len(df_clean)*100:.1f}%)\")\n",
    "    \n",
    "    # Show nutritional column statistics\n",
    "    nutrition_cols = ['calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'sodium', 'cholesterol']\n",
    "    available_nutrition_cols = [col for col in nutrition_cols if col in df_clean.columns]\n",
    "    \n",
    "    if available_nutrition_cols:\n",
    "        print(f\"\\nNutritional data availability:\")\n",
    "        for col in available_nutrition_cols:\n",
    "            non_null_count = df_clean[col].notna().sum()\n",
    "            print(f\"  - {col}: {non_null_count}/{len(df_clean)} ({non_null_count/len(df_clean)*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample of cleaned food items\n",
    "    print(f\"\\nSample of cleaned food items (first 15):\")\n",
    "    for i, item in enumerate(df_clean['food_item'].head(15)):\n",
    "        print(f\"  {i+1:2d}. {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6c708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANING NUTRITIONAL VALUES:\n",
      "==================================================\n",
      "Found nutritional columns: ['calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'sodium', 'cholesterol']\n",
      "\n",
      "Cleaning column: calories\n",
      "Sample values before cleaning:\n",
      "  1. '755'\n",
      "  2. '264'\n",
      "  3. '678'\n",
      "  4. '334'\n",
      "  5. '500'\n",
      "Results:\n",
      "  - Original non-null values: 8525\n",
      "  - Cleaned non-null values: 8525\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 755.0\n",
      "  2. 264.0\n",
      "  3. 678.0\n",
      "  4. 334.0\n",
      "  5. 500.0\n",
      "\n",
      "Cleaning column: proteins\n",
      "Sample values before cleaning:\n",
      "  1. '24'\n",
      "  2. '4'\n",
      "  3. '38'\n",
      "  4. '13'\n",
      "  5. '8'\n",
      "Results:\n",
      "  - Original non-null values: 8463\n",
      "  - Cleaned non-null values: 8462\n",
      "  - Values lost during cleaning: 1\n",
      "Sample cleaned values:\n",
      "  1. 24.0\n",
      "  2. 4.0\n",
      "  3. 38.0\n",
      "  4. 13.0\n",
      "  5. 8.0\n",
      "\n",
      "Cleaning column: carbohydrates\n",
      "Sample values before cleaning:\n",
      "  1. '109'\n",
      "  2. '32'\n",
      "  3. '49'\n",
      "  4. '49'\n",
      "  5. '72'\n",
      "Results:\n",
      "  - Original non-null values: 8491\n",
      "  - Cleaned non-null values: 8491\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 109.0\n",
      "  2. 32.0\n",
      "  3. 49.0\n",
      "  4. 49.0\n",
      "  5. 72.0\n",
      "\n",
      "Cleaning column: fats\n",
      "Sample values before cleaning:\n",
      "  1. '22'\n",
      "  2. '13'\n",
      "  3. '37'\n",
      "  4. '10'\n",
      "  5. '20'\n",
      "Results:\n",
      "  - Original non-null values: 8392\n",
      "  - Cleaned non-null values: 8392\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 22.0\n",
      "  2. 13.0\n",
      "  3. 37.0\n",
      "  4. 10.0\n",
      "  5. 20.0\n",
      "\n",
      "Cleaning column: fibers\n",
      "Sample values before cleaning:\n",
      "  1. '19'\n",
      "  2. '0'\n",
      "  3. '4'\n",
      "  4. '1'\n",
      "  5. '4'\n",
      "Results:\n",
      "  - Original non-null values: 7631\n",
      "  - Cleaned non-null values: 7631\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "Results:\n",
      "  - Original non-null values: 8463\n",
      "  - Cleaned non-null values: 8462\n",
      "  - Values lost during cleaning: 1\n",
      "Sample cleaned values:\n",
      "  1. 24.0\n",
      "  2. 4.0\n",
      "  3. 38.0\n",
      "  4. 13.0\n",
      "  5. 8.0\n",
      "\n",
      "Cleaning column: carbohydrates\n",
      "Sample values before cleaning:\n",
      "  1. '109'\n",
      "  2. '32'\n",
      "  3. '49'\n",
      "  4. '49'\n",
      "  5. '72'\n",
      "Results:\n",
      "  - Original non-null values: 8491\n",
      "  - Cleaned non-null values: 8491\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 109.0\n",
      "  2. 32.0\n",
      "  3. 49.0\n",
      "  4. 49.0\n",
      "  5. 72.0\n",
      "\n",
      "Cleaning column: fats\n",
      "Sample values before cleaning:\n",
      "  1. '22'\n",
      "  2. '13'\n",
      "  3. '37'\n",
      "  4. '10'\n",
      "  5. '20'\n",
      "Results:\n",
      "  - Original non-null values: 8392\n",
      "  - Cleaned non-null values: 8392\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 22.0\n",
      "  2. 13.0\n",
      "  3. 37.0\n",
      "  4. 10.0\n",
      "  5. 20.0\n",
      "\n",
      "Cleaning column: fibers\n",
      "Sample values before cleaning:\n",
      "  1. '19'\n",
      "  2. '0'\n",
      "  3. '4'\n",
      "  4. '1'\n",
      "  5. '4'\n",
      "Results:\n",
      "  - Original non-null values: 7631\n",
      "  - Cleaned non-null values: 7631\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 19.0\n",
      "  2. 0.0\n",
      "  3. 4.0\n",
      "  4. 1.0\n",
      "  5. 4.0\n",
      "\n",
      "Cleaning column: sugars\n",
      "Sample values before cleaning:\n",
      "  1. '9'\n",
      "  2. '13'\n",
      "  3. '2'\n",
      "  4. '6'\n",
      "  5. '36'\n",
      "  1. 19.0\n",
      "  2. 0.0\n",
      "  3. 4.0\n",
      "  4. 1.0\n",
      "  5. 4.0\n",
      "\n",
      "Cleaning column: sugars\n",
      "Sample values before cleaning:\n",
      "  1. '9'\n",
      "  2. '13'\n",
      "  3. '2'\n",
      "  4. '6'\n",
      "  5. '36'\n",
      "Results:\n",
      "  - Original non-null values: 6811\n",
      "  - Cleaned non-null values: 6811\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 9.0\n",
      "  2. 13.0\n",
      "  3. 2.0\n",
      "  4. 6.0\n",
      "  5. 36.0\n",
      "\n",
      "Cleaning column: sodium\n",
      "Sample values before cleaning:\n",
      "  1. '752'\n",
      "  2. '680'\n",
      "  3. '295'\n",
      "  4. '307'\n",
      "  5. '300'\n",
      "Results:\n",
      "  - Original non-null values: 6811\n",
      "  - Cleaned non-null values: 6811\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 9.0\n",
      "  2. 13.0\n",
      "  3. 2.0\n",
      "  4. 6.0\n",
      "  5. 36.0\n",
      "\n",
      "Cleaning column: sodium\n",
      "Sample values before cleaning:\n",
      "  1. '752'\n",
      "  2. '680'\n",
      "  3. '295'\n",
      "  4. '307'\n",
      "  5. '300'\n",
      "Results:\n",
      "  - Original non-null values: 8254\n",
      "  - Cleaned non-null values: 8253\n",
      "  - Values lost during cleaning: 1\n",
      "Sample cleaned values:\n",
      "  1. 752.0\n",
      "  2. 680.0\n",
      "  3. 295.0\n",
      "  4. 307.0\n",
      "  5. 300.0\n",
      "\n",
      "Cleaning column: cholesterol\n",
      "Sample values before cleaning:\n",
      "  1. '125.0'\n",
      "  2. '97.0'\n",
      "  3. '157.0'\n",
      "  4. '13.0'\n",
      "  5. '244.0'\n",
      "Results:\n",
      "  - Original non-null values: 7199\n",
      "  - Cleaned non-null values: 7199\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 125.0\n",
      "  2. 97.0\n",
      "  3. 157.0\n",
      "  4. 13.0\n",
      "  5. 244.0\n",
      "\n",
      "✅ NUTRITIONAL VALUE CLEANING COMPLETED!\n",
      "Results:\n",
      "  - Original non-null values: 8254\n",
      "  - Cleaned non-null values: 8253\n",
      "  - Values lost during cleaning: 1\n",
      "Sample cleaned values:\n",
      "  1. 752.0\n",
      "  2. 680.0\n",
      "  3. 295.0\n",
      "  4. 307.0\n",
      "  5. 300.0\n",
      "\n",
      "Cleaning column: cholesterol\n",
      "Sample values before cleaning:\n",
      "  1. '125.0'\n",
      "  2. '97.0'\n",
      "  3. '157.0'\n",
      "  4. '13.0'\n",
      "  5. '244.0'\n",
      "Results:\n",
      "  - Original non-null values: 7199\n",
      "  - Cleaned non-null values: 7199\n",
      "  - Values lost during cleaning: 0\n",
      "Sample cleaned values:\n",
      "  1. 125.0\n",
      "  2. 97.0\n",
      "  3. 157.0\n",
      "  4. 13.0\n",
      "  5. 244.0\n",
      "\n",
      "✅ NUTRITIONAL VALUE CLEANING COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "# Clean nutritional values in the dataset\n",
    "print(\"CLEANING NUTRITIONAL VALUES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define nutritional columns that might need cleaning\n",
    "nutrition_cols = ['calories', 'proteins', 'carbohydrates', 'fats', 'fibers', 'sugars', 'sodium', 'cholesterol']\n",
    "available_nutrition_cols = [col for col in nutrition_cols if col in df_clean.columns]\n",
    "\n",
    "print(f\"Found nutritional columns: {available_nutrition_cols}\")\n",
    "\n",
    "# Clean each nutritional column\n",
    "for col in available_nutrition_cols:\n",
    "    print(f\"\\nCleaning column: {col}\")\n",
    "    \n",
    "    # Show some sample values before cleaning\n",
    "    print(f\"Sample values before cleaning:\")\n",
    "    sample_values = df_clean[col].dropna().head(5)\n",
    "    for i, value in enumerate(sample_values):\n",
    "        print(f\"  {i+1}. '{value}'\")\n",
    "    \n",
    "    # Apply cleaning function\n",
    "    original_values = df_clean[col].copy()\n",
    "    df_clean[col] = df_clean[col].apply(clean_nutritional_value)\n",
    "    \n",
    "    # Show results\n",
    "    cleaned_count = df_clean[col].notna().sum()\n",
    "    original_count = original_values.notna().sum()\n",
    "    \n",
    "    print(f\"Results:\")\n",
    "    print(f\"  - Original non-null values: {original_count}\")\n",
    "    print(f\"  - Cleaned non-null values: {cleaned_count}\")\n",
    "    print(f\"  - Values lost during cleaning: {original_count - cleaned_count}\")\n",
    "    \n",
    "    # Show some sample cleaned values\n",
    "    if cleaned_count > 0:\n",
    "        print(f\"Sample cleaned values:\")\n",
    "        sample_cleaned = df_clean[col].dropna().head(5)\n",
    "        for i, value in enumerate(sample_cleaned):\n",
    "            print(f\"  {i+1}. {value}\")\n",
    "\n",
    "print(f\"\\n✅ NUTRITIONAL VALUE CLEANING COMPLETED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2316a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTRITIONAL DATA VERIFICATION:\n",
      "==================================================\n",
      "Data types after cleaning:\n",
      "  - calories: float64\n",
      "  - proteins: float64\n",
      "  - carbohydrates: float64\n",
      "  - fats: float64\n",
      "  - fibers: float64\n",
      "  - sugars: float64\n",
      "  - sodium: float64\n",
      "  - cholesterol: float64\n",
      "\n",
      "Summary statistics for cleaned nutritional data:\n",
      "       calories  proteins  carbohydrates     fats  fibers    sugars    sodium  \\\n",
      "count   8525.00   8462.00        8491.00  8392.00  7631.0   6811.00   8253.00   \n",
      "mean     237.02     17.54          27.74    10.80     2.8     14.61    319.09   \n",
      "std      188.06    717.45         101.58    18.01     5.8    323.82    976.64   \n",
      "min        0.00      0.00           0.00     0.00     0.0      0.00      0.00   \n",
      "25%       81.00      1.96           3.11     0.69     0.0      0.33     14.00   \n",
      "50%      193.00      6.40          13.86     4.40     1.2      3.13     97.00   \n",
      "75%      369.00     14.95          51.74    14.12     3.1     12.70    415.00   \n",
      "max     2236.00  66000.00        9000.00   646.00    86.0  26700.00  38758.00   \n",
      "\n",
      "       cholesterol  \n",
      "count      7199.00  \n",
      "mean         36.35  \n",
      "std         128.55  \n",
      "min           0.00  \n",
      "25%           0.00  \n",
      "50%           0.00  \n",
      "75%          51.00  \n",
      "max        3100.00  \n",
      "\n",
      "Checking for any remaining non-numeric values:\n",
      "  ✅ calories: All values are numeric or NaN\n",
      "  ✅ proteins: All values are numeric or NaN\n",
      "  ✅ carbohydrates: All values are numeric or NaN\n",
      "  ✅ fats: All values are numeric or NaN\n",
      "  ✅ fibers: All values are numeric or NaN\n",
      "  ✅ sugars: All values are numeric or NaN\n",
      "  ✅ sodium: All values are numeric or NaN\n",
      "  ✅ cholesterol: All values are numeric or NaN\n",
      "\n",
      "🎉 NUTRITIONAL DATA VERIFICATION COMPLETED!\n",
      "       calories  proteins  carbohydrates     fats  fibers    sugars    sodium  \\\n",
      "count   8525.00   8462.00        8491.00  8392.00  7631.0   6811.00   8253.00   \n",
      "mean     237.02     17.54          27.74    10.80     2.8     14.61    319.09   \n",
      "std      188.06    717.45         101.58    18.01     5.8    323.82    976.64   \n",
      "min        0.00      0.00           0.00     0.00     0.0      0.00      0.00   \n",
      "25%       81.00      1.96           3.11     0.69     0.0      0.33     14.00   \n",
      "50%      193.00      6.40          13.86     4.40     1.2      3.13     97.00   \n",
      "75%      369.00     14.95          51.74    14.12     3.1     12.70    415.00   \n",
      "max     2236.00  66000.00        9000.00   646.00    86.0  26700.00  38758.00   \n",
      "\n",
      "       cholesterol  \n",
      "count      7199.00  \n",
      "mean         36.35  \n",
      "std         128.55  \n",
      "min           0.00  \n",
      "25%           0.00  \n",
      "50%           0.00  \n",
      "75%          51.00  \n",
      "max        3100.00  \n",
      "\n",
      "Checking for any remaining non-numeric values:\n",
      "  ✅ calories: All values are numeric or NaN\n",
      "  ✅ proteins: All values are numeric or NaN\n",
      "  ✅ carbohydrates: All values are numeric or NaN\n",
      "  ✅ fats: All values are numeric or NaN\n",
      "  ✅ fibers: All values are numeric or NaN\n",
      "  ✅ sugars: All values are numeric or NaN\n",
      "  ✅ sodium: All values are numeric or NaN\n",
      "  ✅ cholesterol: All values are numeric or NaN\n",
      "\n",
      "🎉 NUTRITIONAL DATA VERIFICATION COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "# Verify the cleaned nutritional data\n",
    "print(\"NUTRITIONAL DATA VERIFICATION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check data types of nutritional columns\n",
    "print(\"Data types after cleaning:\")\n",
    "for col in available_nutrition_cols:\n",
    "    dtype = df_clean[col].dtype\n",
    "    print(f\"  - {col}: {dtype}\")\n",
    "\n",
    "# Show summary statistics for nutritional columns\n",
    "print(\"\\nSummary statistics for cleaned nutritional data:\")\n",
    "nutrition_stats = df_clean[available_nutrition_cols].describe()\n",
    "print(nutrition_stats.round(2))\n",
    "\n",
    "# Check for any non-numeric values that might have slipped through\n",
    "print(\"\\nChecking for any remaining non-numeric values:\")\n",
    "for col in available_nutrition_cols:\n",
    "    non_numeric = df_clean[col].apply(lambda x: not (pd.isna(x) or isinstance(x, (int, float))))\n",
    "    non_numeric_count = non_numeric.sum()\n",
    "    if non_numeric_count > 0:\n",
    "        print(f\"  ⚠️  {col}: {non_numeric_count} non-numeric values found\")\n",
    "        # Show examples\n",
    "        examples = df_clean[non_numeric][col].head(3)\n",
    "        for i, val in enumerate(examples):\n",
    "            print(f\"    Example {i+1}: '{val}' (type: {type(val)})\")\n",
    "    else:\n",
    "        print(f\"  ✅ {col}: All values are numeric or NaN\")\n",
    "\n",
    "print(f\"\\n🎉 NUTRITIONAL DATA VERIFICATION COMPLETED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35184034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL QUALITY CHECK:\n",
      "==================================================\n",
      "Remaining food items with special characters: 0\n",
      "Remaining invalid food names: 0\n",
      "Remaining duplicate food items: 0\n",
      "Missing food items: 0\n",
      "\n",
      "✅ QUALITY CHECK PASSED - Dataset is clean!\n",
      "\n",
      "FINAL STATISTICS:\n",
      "- Total food items: 8,681\n",
      "- Unique food items: 8,681\n",
      "- Average food name length: 34.4 characters\n",
      "- Shortest food name: 'Pie' (3 chars)\n",
      "- Longest food name: 'Continental This is Caramel coffee - Continental Coffee Limited - 22g' (69 chars)\n",
      "- Unique food items: 8,681\n",
      "- Average food name length: 34.4 characters\n",
      "- Shortest food name: 'Pie' (3 chars)\n",
      "- Longest food name: 'Continental This is Caramel coffee - Continental Coffee Limited - 22g' (69 chars)\n"
     ]
    }
   ],
   "source": [
    "# Quality check - look for any remaining issues\n",
    "print(\"FINAL QUALITY CHECK:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for any remaining special characters\n",
    "remaining_special = df_clean['food_item'].apply(has_special_characters).sum()\n",
    "print(f\"Remaining food items with special characters: {remaining_special}\")\n",
    "\n",
    "# Check for any remaining invalid names\n",
    "remaining_invalid = (~df_clean['food_item'].apply(is_valid_food_name)).sum()\n",
    "print(f\"Remaining invalid food names: {remaining_invalid}\")\n",
    "\n",
    "# Check for any remaining duplicates\n",
    "remaining_duplicates = df_clean.duplicated(subset=['food_item']).sum()\n",
    "print(f\"Remaining duplicate food items: {remaining_duplicates}\")\n",
    "\n",
    "# Check for any missing values in food_item\n",
    "missing_food_items = df_clean['food_item'].isna().sum()\n",
    "print(f\"Missing food items: {missing_food_items}\")\n",
    "\n",
    "if remaining_special == 0 and remaining_invalid == 0 and remaining_duplicates == 0 and missing_food_items == 0:\n",
    "    print(f\"\\n✅ QUALITY CHECK PASSED - Dataset is clean!\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  QUALITY CHECK ISSUES FOUND - Manual review may be needed\")\n",
    "\n",
    "# Show some statistics about the cleaned data\n",
    "print(f\"\\nFINAL STATISTICS:\")\n",
    "print(f\"- Total food items: {len(df_clean):,}\")\n",
    "print(f\"- Unique food items: {df_clean['food_item'].nunique():,}\")\n",
    "print(f\"- Average food name length: {df_clean['food_item'].str.len().mean():.1f} characters\")\n",
    "\n",
    "if len(df_clean) > 0:\n",
    "    shortest_idx = df_clean['food_item'].str.len().idxmin()\n",
    "    longest_idx = df_clean['food_item'].str.len().idxmax()\n",
    "    print(f\"- Shortest food name: '{df_clean.loc[shortest_idx, 'food_item']}' ({df_clean['food_item'].str.len().min()} chars)\")\n",
    "    print(f\"- Longest food name: '{df_clean.loc[longest_idx, 'food_item']}' ({df_clean['food_item'].str.len().max()} chars)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f2be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING CLEANED DATASET:\n",
      "==================================================\n",
      "✅ Cleaned dataset saved to: ../../dataset/childs/final_clean_food_dataset.csv\n",
      "📄 File size: 773,757 bytes (0.74 MB)\n",
      "📊 Total rows: 8,681\n",
      "📋 Total columns: 13\n",
      "🍎 Unique food items: 8,681\n",
      "\n",
      "Saved columns:\n",
      "   1. food_item (object) - 8,681/8,681 values (100.0%)\n",
      "   2. calories (float64) - 8,525/8,681 values (98.2%)\n",
      "   3. proteins (float64) - 8,462/8,681 values (97.5%)\n",
      "   4. carbohydrates (float64) - 8,491/8,681 values (97.8%)\n",
      "   5. fats (float64) - 8,392/8,681 values (96.7%)\n",
      "   6. fibers (float64) - 7,631/8,681 values (87.9%)\n",
      "   7. sugars (float64) - 6,811/8,681 values (78.5%)\n",
      "   8. category (object) - 35/8,681 values (0.4%)\n",
      "   9. sodium (float64) - 8,253/8,681 values (95.1%)\n",
      "  10. cholesterol (float64) - 7,199/8,681 values (82.9%)\n",
      "  11. meal_type (object) - 35/8,681 values (0.4%)\n",
      "  12. water_intake (float64) - 35/8,681 values (0.4%)\n",
      "  13. source_file (object) - 8,681/8,681 values (100.0%)\n",
      "\n",
      "Verifying saved file...\n",
      "✓ Verification successful - loaded 8,681 rows and 13 columns\n",
      "\n",
      "📁 Full file path: d:\\Code\\Lychee\\lychee-meal-planners\\systems\\dataset\\childs\\final_clean_food_dataset.csv\n",
      "\n",
      "🎉 DATASET CLEANING AND EXPORT COMPLETED SUCCESSFULLY!\n",
      "Original dataset: 20,944 rows\n",
      "Final dataset: 8,681 rows\n",
      "Reduction: 12,263 rows (58.6%)\n",
      "\n",
      "✨ The cleaned dataset is ready for production use!\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "output_file = '../../dataset/childs/final_clean_food_dataset.csv'\n",
    "print(f\"SAVING CLEANED DATASET:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Save to CSV\n",
    "df_clean.to_csv(output_file, index=False)\n",
    "import os\n",
    "file_size = os.path.getsize(output_file)\n",
    "\n",
    "print(f\"✅ Cleaned dataset saved to: {output_file}\")\n",
    "print(f\"📄 File size: {file_size:,} bytes ({file_size / 1024 / 1024:.2f} MB)\")\n",
    "print(f\"📊 Total rows: {len(df_clean):,}\")\n",
    "print(f\"📋 Total columns: {len(df_clean.columns)}\")\n",
    "print(f\"🍎 Unique food items: {df_clean['food_item'].nunique():,}\")\n",
    "\n",
    "# Show column details\n",
    "print(f\"\\nSaved columns:\")\n",
    "for i, col in enumerate(df_clean.columns, 1):\n",
    "    non_null_count = df_clean[col].notna().sum()\n",
    "    data_type = df_clean[col].dtype\n",
    "    print(f\"  {i:2d}. {col} ({data_type}) - {non_null_count:,}/{len(df_clean):,} values ({non_null_count/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "# Verify the saved file\n",
    "print(f\"\\nVerifying saved file...\")\n",
    "df_verify = pd.read_csv(output_file)\n",
    "print(f\"✓ Verification successful - loaded {len(df_verify):,} rows and {len(df_verify.columns)} columns\")\n",
    "\n",
    "# Show file path for easy access\n",
    "import os\n",
    "full_path = os.path.abspath(output_file)\n",
    "print(f\"\\n📁 Full file path: {full_path}\")\n",
    "\n",
    "print(f\"\\n🎉 DATASET CLEANING AND EXPORT COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"Original dataset: {initial_count:,} rows\") \n",
    "print(f\"Final dataset: {len(df_clean):,} rows\")\n",
    "print(f\"Reduction: {initial_count - len(df_clean):,} rows ({(initial_count - len(df_clean))/initial_count*100:.1f}%)\")\n",
    "print(f\"\\n✨ The cleaned dataset is ready for production use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90e2e8",
   "metadata": {},
   "source": [
    "# 🎉 Dataset Cleaning Summary\n",
    "\n",
    "## Cleaning Operations Performed\n",
    "\n",
    "1. **Removed Invalid Food Names** - Filtered out empty, numeric-only, or too-short food names\n",
    "2. **Removed Special Characters** - Eliminated food items with special characters (keeping only letters, numbers, and common food punctuation)\n",
    "3. **Removed Duplicates** - Eliminated exact duplicate rows and duplicate food items\n",
    "4. **Cleaned Nutritional Values** - Removed units from all nutritional columns and converted to numeric format\n",
    "5. **Quality Verification** - Ensured all data meets production standards\n",
    "\n",
    "## Results\n",
    "\n",
    "- **Input File**: `../../dataset/childs/unified_food_dataset.csv`\n",
    "- **Output File**: `../../dataset/childs/final_clean_food_dataset.csv`\n",
    "- **Original Rows**: 20,944\n",
    "- **Final Rows**: 8,681 (58.6% reduction)\n",
    "- **Unique Food Items**: 8,681\n",
    "- **File Size**: 0.74 MB\n",
    "\n",
    "## Data Quality\n",
    "\n",
    "✅ **All nutritional values are numeric** (units removed)  \n",
    "✅ **No duplicate food items**  \n",
    "✅ **No special characters in food names**  \n",
    "✅ **All food names are valid**  \n",
    "✅ **Data types are optimized for analysis**\n",
    "\n",
    "## Ready for Production Use\n",
    "\n",
    "The cleaned dataset is now ready for:\n",
    "\n",
    "- Machine learning model training\n",
    "- Nutritional analysis\n",
    "- Meal planning algorithms\n",
    "- Data visualization\n",
    "- API integration\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
